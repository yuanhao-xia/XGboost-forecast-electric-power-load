import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import xgboost as xgb
from xgboost import XGBRegressor
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
import warnings
warnings.filterwarnings('ignore')
sns.set_style("whitegrid")
plt.rcParams['font.sans-serif'] = ['SimHei']  # ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['axes.unicode_minus'] = False

# ======================
# 2. ç”Ÿæˆç¬¦åˆå±…æ°‘ç”¨ç”µç‰¹æ€§çš„æ¨¡æ‹Ÿæ•°æ®é›†
# ======================
def generate_electricity_load(start_date='2023-01-01', days=365):
    """
    ç”Ÿæˆå…·æœ‰çœŸå®æ„Ÿçš„å±…æ°‘ç”¨ç”µè´Ÿè·æ•°æ®ï¼ˆå•ä½ï¼škWï¼‰
    ç‰¹æ€§ï¼šæ—¥å‘¨æœŸæ€§ã€å‘¨å‘¨æœŸæ€§ã€å‘¨æœ«æ•ˆåº”ã€è¶‹åŠ¿ã€å™ªå£°
    """
    np.random.seed(42)
    hours = days * 24
    time_index = pd.date_range(start=start_date, periods=hours, freq='H')
    
    # åŸºç¡€è´Ÿè·ï¼ˆå‡å€¼2.0ï¼‰
    base_load = 2.0
    
    # æ—¥å‘¨æœŸæ€§ï¼ˆæŒ¯å¹…0.8ï¼Œå±…æ°‘ç™½å¤©é«˜ã€å¤œé—´ä½ï¼‰
    hour_sin = np.sin(2 * np.pi * (np.arange(hours) % 24) / 24)
    daily_pattern = 0.8 * hour_sin
    
    # å‘¨å‘¨æœŸæ€§ï¼ˆå·¥ä½œæ—¥é«˜ã€å‘¨æœ«ä½ï¼ŒæŒ¯å¹…0.5ï¼‰
    day_of_week = time_index.dayofweek  # 0=å‘¨ä¸€, 6=å‘¨æ—¥
    weekly_pattern = 0.5 * np.sin(2 * np.pi * day_of_week / 7)
    
    # å‘¨æœ«æ•ˆåº”ï¼ˆå‘¨å…­æ—¥é™ä½20%ï¼‰
    weekend_mask = (day_of_week >= 5).astype(int)  # å‘¨å…­æ—¥ä¸º1
    weekend_effect = -0.4 * weekend_mask
    
    # ç¼“æ…¢å¢é•¿è¶‹åŠ¿ï¼ˆæ¨¡æ‹Ÿç”¨æˆ·å¢é•¿ï¼‰
    trend = 0.0005 * np.arange(hours)
    
    # éšæœºå™ªå£°ï¼ˆé«˜æ–¯+å¶å°”å°–å³°ï¼‰
    noise = 0.15 * np.random.randn(hours)
    spike_events = (np.random.rand(hours) < 0.01).astype(int) * np.random.uniform(0.3, 0.8, hours)
    
    # åˆæˆè´Ÿè·ï¼ˆç¡®ä¿>0ï¼‰
    load = base_load + daily_pattern + weekly_pattern + weekend_effect + trend + noise + spike_events
    load = np.maximum(load, 0.3)  # é¿å…è´Ÿå€¼
    
    # åˆ›å»ºDataFrame
    df = pd.DataFrame({
        'datetime': time_index,
        'load': load
    })
    df.set_index('datetime', inplace=True)
    return df

excel_file_path = r'C:\Users\lenovo\Desktop\ç¬¬30æœŸå¤§åˆ›ç«‹é¡¹å¤šæ™ºèƒ½ä½“ååŒä¼˜åŒ–\æ•°æ®æ±‡æ€».xlsx'  # è¯·æ›¿æ¢ä¸ºä½ çš„å®é™…æ–‡ä»¶è·¯å¾„


try:
    # è¯»å–Excelæ•°æ®
    time_data = pd.read_excel(excel_file_path, sheet_name='æ•°æ®æ±‡æ€»', header=None)
    electricity_load = time_data.iloc[1:8761, 1].values.astype(float)  # è¯»å–ç¬¬ä¸€åˆ—æ•°æ®
    
    # åˆ›å»ºDataFrameæ›¿æ¢åŸæœ‰df
    start_date = '2023-01-01'
    time_index = pd.date_range(start=start_date, periods=len(electricity_load), freq='H')
    df = pd.DataFrame({
        'datetime': time_index,
        'load': electricity_load
    })
    df.set_index('datetime', inplace=True)
    
    print("âœ… çœŸå®æ•°æ®åŠ è½½æˆåŠŸï¼")
    print(f"æ•°æ®å½¢çŠ¶: {df.shape} | æ—¶é—´èŒƒå›´: {df.index.min()} è‡³ {df.index.max()}")
    print(f"è´Ÿè·ç»Ÿè®¡: æœ€å°={df['load'].min():.2f}kW, æœ€å¤§={df['load'].max():.2f}kW, å‡å€¼={df['load'].mean():.2f}kW")
    
except Exception as e:
    print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
    print("ä½¿ç”¨åŸå§‹æ¨¡æ‹Ÿæ•°æ®...")
    df = generate_electricity_load(days=365)  # å¤‡ç”¨æ–¹æ¡ˆ
    print(f"æ•°æ®å½¢çŠ¶: {df.shape} | æ—¶é—´èŒƒå›´: {df.index.min()} è‡³ {df.index.max()}")
    print(f"è´Ÿè·ç»Ÿè®¡: æœ€å°={df['load'].min():.2f}kW, æœ€å¤§={df['load'].max():.2f}kW, å‡å€¼={df['load'].mean():.2f}kW")

# ======================
# 3. å¯è§†åŒ–åŸå§‹æ•°æ®ï¼ˆéªŒè¯åˆç†æ€§ï¼‰
# ======================
def plot_sample_data(df):
    fig, axes = plt.subplots(3, 1, figsize=(14, 10))
    
    # å…¨å¹´è¶‹åŠ¿
    axes[0].plot(df.index, df['load'], linewidth=0.8, color='steelblue')
    axes[0].set_title('å…¨å¹´ç”¨ç”µè´Ÿè·è¶‹åŠ¿', fontsize=14)
    axes[0].set_ylabel('è´Ÿè· (kW)')
    
    # ä¸€å‘¨ç¤ºä¾‹ï¼ˆç¬¬10å‘¨ï¼‰
    week_sample = df['2023-03-06':'2023-03-12']  # é€‰ä¸€å‘¨
    axes[1].plot(week_sample.index, week_sample['load'], marker='o', markersize=3)
    axes[1].set_title('å•å‘¨è´Ÿè·æ³¢åŠ¨ï¼ˆå±•ç¤ºæ—¥å‘¨æœŸæ€§ï¼‰', fontsize=14)
    axes[1].set_ylabel('è´Ÿè· (kW)')
    axes[1].grid(True, linestyle='--', alpha=0.7)
    
    # ä¸€æ—¥ç¤ºä¾‹ï¼ˆå·¥ä½œæ—¥ï¼‰
    day_sample = df['2023-03-08 00:00':'2023-03-08 23:00']
    axes[2].plot(day_sample.index, day_sample['load'], 'ro-', linewidth=2)
    axes[2].set_title('å•æ—¥è´Ÿè·æ›²çº¿ï¼ˆå…¸å‹å·¥ä½œæ—¥ï¼‰', fontsize=14)
    axes[2].set_ylabel('è´Ÿè· (kW)')
    axes[2].set_xlabel('æ—¶é—´')
    axes[2].grid(True, linestyle='--', alpha=0.7)
    
    plt.tight_layout()
    plt.savefig('load_patterns.png', dpi=300, bbox_inches='tight')
    plt.show()

plot_sample_data(df)

# ======================
# 4. æ•°æ®é¢„å¤„ç†ï¼šå½’ä¸€åŒ– + æ„é€ ç›‘ç£å­¦ä¹ æ ·æœ¬
# ======================
def create_dataset(df, look_back=168, look_forward=24):
    """
    å°†æ—¶é—´åºåˆ—è½¬æ¢ä¸ºç›‘ç£å­¦ä¹ æ ¼å¼
    X: [æ ·æœ¬æ•°, look_back, ç‰¹å¾æ•°]  -> è¿‡å»168å°æ—¶
    y: [æ ·æœ¬æ•°, look_forward]       -> æœªæ¥24å°æ—¶
    """
    data = df.copy()
    data['hour'] = data.index.hour
    data['dayofweek'] = data.index.dayofweek  # 0=å‘¨ä¸€, 6=å‘¨æ—¥

    # å½’ä¸€åŒ–è´Ÿè·ï¼ˆå…¶ä»–ç‰¹å¾ä¸å½’ä¸€åŒ–ï¼ŒXGBoost å¯¹å°ºåº¦é²æ£’ï¼‰
    scaler = MinMaxScaler(feature_range=(0, 1))
    load_scaled = scaler.fit_transform(data[['load']]).flatten()

    # æ„é€ ç‰¹å¾çŸ©é˜µ: [load_scaled, hour, dayofweek]
    features = np.column_stack([
        load_scaled,
        data['hour'].values,
        data['dayofweek'].values
    ])  # shape: [T, 3]

    X, y = [], []
    total_len = len(features)
    for i in range(total_len - look_back - look_forward + 1):
        X.append(features[i:(i + look_back)])          # [168, 3]
        y.append(load_scaled[(i + look_back):(i + look_back + look_forward)])  # [24,]
    
    return np.array(X), np.array(y), scaler


# æ„é€ æ ·æœ¬ï¼šè¾“å…¥168å°æ—¶ï¼Œé¢„æµ‹24å°æ—¶
LOOK_BACK = 168  # 7å¤©å†å²
LOOK_FORWARD = 24  # é¢„æµ‹24å°æ—¶
X, y, scaler = create_dataset(df, LOOK_BACK, LOOK_FORWARD)

print(f"\nâœ… æ ·æœ¬æ„é€ å®Œæˆï¼")
print(f"è¾“å…¥Xå½¢çŠ¶: {X.shape} -> (æ ·æœ¬æ•°, æ—¶é—´æ­¥168, ç‰¹å¾3)")
print(f"è¾“å‡ºyå½¢çŠ¶: {y.shape} -> (æ ·æœ¬æ•°, é¢„æµ‹æ­¥é•¿24)")
print(f"æ€»æ ·æœ¬æ•°: {len(X)} | å¯è¦†ç›– {len(X)/24:.1f} å¤©çš„è®­ç»ƒçª—å£")

# ======================
# 5. ä¸¥æ ¼æŒ‰æ—¶é—´é¡ºåºåˆ’åˆ†æ•°æ®é›†ï¼ˆç¦æ­¢shuffle!ï¼‰
# ======================
# è®¡ç®—åˆ’åˆ†ç‚¹ï¼ˆ70%è®­ç»ƒ, 15%éªŒè¯, 15%æµ‹è¯•ï¼‰
train_size = int(len(X) * 0.7)
val_size = int(len(X) * 0.15)

X_train, y_train = X[:train_size], y[:train_size]
X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]
X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]

print(f"\nâœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼ˆä¸¥æ ¼æ—¶åºï¼‰:")
print(f"è®­ç»ƒé›†: {X_train.shape} | éªŒè¯é›†: {X_val.shape} | æµ‹è¯•é›†: {X_test.shape}")

# ======================
# 6. æ„å»ºXGBoostæ¨¡å‹ï¼ˆåº•å±‚APIï¼Œå½»åº•è§„é¿ç‰ˆæœ¬é™·é˜±ï¼‰
# ======================
print("\nğŸ”„ å‡†å¤‡XGBoostè®­ç»ƒæ•°æ®ï¼ˆé‡å¡‘ä¸ºäºŒç»´ç‰¹å¾ï¼‰...")
X_train_reshaped = X_train.reshape(X_train.shape[0], -1)
X_val_reshaped = X_val.reshape(X_val.shape[0], -1)
X_test_reshaped = X_test.reshape(X_test.shape[0], -1)
print(f"âœ… é‡å¡‘å®Œæˆ | è®­ç»ƒé›†: {X_train_reshaped.shape} | éªŒè¯é›†: {X_val_reshaped.shape}")

# ======================
# 7. è®­ç»ƒ24ä¸ªXGBoostæ¨¡å‹ï¼ˆxgb.train + DMatrixï¼Œå…¨ç‰ˆæœ¬å…¼å®¹ï¼‰
# ======================
print("\nğŸš€ å¼€å§‹è®­ç»ƒ24ä¸ªXGBoostæ¨¡å‹ï¼ˆåº•å±‚APIï¼Œå…¼å®¹æ‰€æœ‰XGBoostç‰ˆæœ¬ï¼‰...")
models = []
best_iters = []
eval_history = {}  # ä»…å­˜ç¬¬1ä¸ªæ¨¡å‹çš„è®­ç»ƒæ›²çº¿

base_params = {
    'objective': 'reg:squarederror',
    'learning_rate': 0.15,
    'max_depth': 8,
    'subsample': 0.85,
    'colsample_bytree': 0.85,
    'alpha': 0.1,
    'lambda': 1.0,
    'random_state': 42,
    'tree_method': 'auto',  # 3.1.1 è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ ‘æ„å»ºæ–¹æ³•
    'nthread': -1
}
extreme_percentile = 90  # å®šä¹‰æå€¼é˜ˆå€¼ç™¾åˆ†ä½
peak_t_steps = {6, 7, 8, 9}
for t in range(LOOK_FORWARD):
    print(f"  [æ¨¡å‹ {t+1:2d}/24] è®­ç»ƒä¸­... (é¢„æµ‹æœªæ¥ç¬¬{t+1}å°æ—¶)", end='\r')
    
    # æ ·æœ¬æƒé‡ï¼šå°–å³°ç›®æ ‡æ—¶åˆ»æƒé‡=5.0ï¼Œå…¶ä»–=1.0
    sample_weights = np.ones(len(y_train))

    if t in peak_t_steps:
        # å¯é€‰ï¼šä¸´æ—¶è°ƒæ•´å‚æ•°ï¼ˆå¦‚æ›´æ·±æ ‘ï¼‰
        params = base_params.copy()
        params['max_depth'] = 12  # æ¯”åŸºç¡€æ·±1å±‚ï¼Œå¢å¼ºæ‹Ÿåˆèƒ½åŠ›
        params['learning_rate'] = 0.15  # æ›´å°å­¦ä¹ ç‡ï¼Œç¨³å®šè®­ç»ƒ
    else:
        params = base_params

    dtrain = xgb.DMatrix(X_train_reshaped, label=y_train[:, t], weight=sample_weights)
    dval = xgb.DMatrix(X_val_reshaped, label=y_val[:, t])
    evals = [(dtrain, 'train'), (dval, 'val')]
    evals_result = {}
    
    # æ ¸å¿ƒï¼šä½¿ç”¨ early_stopping_roundsï¼ˆåº•å±‚APIç¨³å®šæ”¯æŒï¼Œæ— callbackså‚æ•°ï¼‰
    bst = xgb.train(
        params,
        dtrain,
        num_boost_round=1000,
        evals=evals,
        evals_result=evals_result,
        early_stopping_rounds=25,  # âœ… æ‰€æœ‰ç‰ˆæœ¬å‡æ”¯æŒæ­¤å‚æ•°
        verbose_eval=False
    )
    
    models.append(bst)
    best_iter = bst.best_iteration if hasattr(bst, 'best_iteration') else len(evals_result['val']['rmse']) - 1
    best_iters.append(best_iter)
    
    if t == 0:
        eval_history = evals_result

print("\nâœ… 24ä¸ªXGBoostæ¨¡å‹è®­ç»ƒå®Œæˆï¼")
print(f"ğŸ“Š æ¨¡å‹ç»Ÿè®¡ | å¹³å‡æœ€ä½³æ ‘æ•°: {int(np.mean(best_iters))} | èŒƒå›´: [{min(best_iters)}, {max(best_iters)}]")

# ======================
# 8. ç”Ÿæˆè®­ç»ƒæ›²çº¿ï¼ˆå…¼å®¹åŸæ–‡ä»¶åï¼‰
# ======================
if eval_history and 'val' in eval_history and 'rmse' in eval_history['val']:
    plt.figure(figsize=(12, 4))
    val_rmse = eval_history['val']['rmse']
    plt.plot(val_rmse, label='è®­ç»ƒæŸå¤±', linewidth=2)
    best_round = np.argmin(val_rmse)
    plt.axvline(x=best_round, color='red', linestyle='--', linewidth=1.5, label=f'æœ€ä½³è¿­ä»£ ({best_round})')
    plt.scatter([best_round], [val_rmse[best_round]], color='red', s=100, zorder=5)
    plt.title('XGBoostæ¨¡å‹è®­ç»ƒç›‘æ§ï¼ˆç¬¬1å°æ—¶é¢„æµ‹æ¨¡å‹ï¼‰', fontsize=14)
    plt.xlabel('Boosting Rounds')
    plt.ylabel('RMSE')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.tight_layout()
    plt.savefig('training_loss.png', dpi=300, bbox_inches='tight')
    plt.show()
else:
    print("âš ï¸  æ— æ³•ç”Ÿæˆè®­ç»ƒæ›²çº¿ï¼ˆevals_result æœªæ•è·ï¼‰")

# ======================
# 9. æ¨¡å‹è¯„ä¼°ï¼ˆå…³é”®ï¼šä½¿ç”¨æœ€ä½³è¿­ä»£è½®æ•°é¢„æµ‹ï¼‰
# ======================
print("\nğŸ” ç”Ÿæˆæµ‹è¯•é›†é¢„æµ‹ç»“æœï¼ˆä½¿ç”¨éªŒè¯é›†æœ€ä¼˜æ¨¡å‹ï¼‰...")
dtest = xgb.DMatrix(X_test_reshaped)
y_pred_scaled = np.column_stack([
    model.predict(dtest, iteration_range=(0, model.best_iteration + 1))  # 3.1.1 æ¨èç”¨æ³•
    for model in models
])
print(f"âœ… é¢„æµ‹å®Œæˆ | å½¢çŠ¶: {y_pred_scaled.shape}")

# åå½’ä¸€åŒ–åˆ°åŸå§‹å°ºåº¦
y_test_inv = scaler.inverse_transform(y_test)  
y_pred_inv = scaler.inverse_transform(y_pred_scaled)
y_pred_inv[:,6]*=1.1  # å¯é€‰ï¼šå¯¹ç¬¬7å°æ—¶çš„é¢„æµ‹ç»“æœè¿›è¡Œå¾®è°ƒï¼Œæ¨¡æ‹Ÿæ›´é«˜å³°å€¼
y_pred_inv[:,7]*=1.1

# è®¡ç®—æ•´ä½“æŒ‡æ ‡ï¼ˆå°†æ‰€æœ‰é¢„æµ‹ç‚¹å±•å¹³è®¡ç®—ï¼‰
flat_true = y_test_inv.flatten()
flat_pred = y_pred_inv.flatten()
mae = mean_absolute_error(flat_true, flat_pred)
rmse = np.sqrt(mean_squared_error(flat_true, flat_pred))
r2 = r2_score(flat_true, flat_pred)

print(f"\nâœ… æµ‹è¯•é›†è¯„ä¼°ç»“æœï¼ˆåå½’ä¸€åŒ–åï¼‰:")
print(f"MAE: {mae:.3f} kW | RMSE: {rmse:.3f} kW | RÂ²: {r2:.4f}")

# æ‰“å°é¢„æµ‹å€¼çš„24ä¸ªç‚¹
print(f"\nğŸ“Š æµ‹è¯•é›†ç¬¬1ä¸ªæ ·æœ¬çš„24å°æ—¶é¢„æµ‹ç»“æœ:")
print("=" * 50)
for i, (true_val, pred_val) in enumerate(zip(y_test_inv[0], y_pred_inv[0])):
    hour = i + 1
    error = abs(true_val - pred_val)
    print(f"ç¬¬{hour:2d}å°æ—¶ | çœŸå®å€¼: {true_val:6.2f}kW | é¢„æµ‹å€¼: {pred_val:6.2f}kW | è¯¯å·®: {error:5.2f}kW")

# è®¡ç®—å¹¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
mae_sample = mean_absolute_error(y_test_inv[0], y_pred_inv[0])
rmse_sample = np.sqrt(mean_squared_error(y_test_inv[0], y_pred_inv[0]))
print("=" * 50)
print(f"ğŸ“Š è¯¥æ ·æœ¬ç»Ÿè®¡æŒ‡æ ‡:")
print(f"å¹³å‡ç»å¯¹è¯¯å·®(MAE): {mae_sample:.3f} kW")
print(f"å‡æ–¹æ ¹è¯¯å·®(RMSE): {rmse_sample:.3f} kW")
print(f"æœ€å¤§è¯¯å·®: {np.max(np.abs(y_test_inv[0] - y_pred_inv[0])):.3f} kW")
print(f"æœ€å°è¯¯å·®: {np.min(np.abs(y_test_inv[0] - y_pred_inv[0])):.3f} kW")

print(f"\nğŸ“‹ å…¶ä»–æ ·æœ¬é¢„æµ‹ç¤ºä¾‹:")
print("-" * 30)
for sample_idx in [1, 2, 3]:  # æ˜¾ç¤ºå‰3ä¸ªæµ‹è¯•æ ·æœ¬
    if sample_idx < len(y_test_inv):
        sample_mae = mean_absolute_error(y_test_inv[sample_idx], y_pred_inv[sample_idx])
        print(f"æµ‹è¯•æ ·æœ¬{sample_idx}: MAE={sample_mae:.3f}kW")

# å¯è§†åŒ–ï¼šé¢„æµ‹æ•ˆæœå¯¹æ¯”ï¼ˆé€‰å–æµ‹è¯•é›†ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼‰
plt.figure(figsize=(14, 6))
hours = np.arange(1, LOOK_FORWARD + 1)
plt.plot(hours, y_test_inv[0], 'bo-', label='çœŸå®å€¼', linewidth=2, markersize=6)
plt.plot(hours, y_pred_inv[0], 'r^--', label='é¢„æµ‹å€¼', linewidth=2, markersize=6)
plt.title(f'æœªæ¥24å°æ—¶è´Ÿè·é¢„æµ‹ç¤ºä¾‹ï¼ˆæµ‹è¯•é›†ç¬¬1ä¸ªæ ·æœ¬ï¼‰\nMAE={mean_absolute_error(y_test_inv[0], y_pred_inv[0]):.3f}kW', fontsize=14)
plt.xlabel('æœªæ¥å°æ—¶æ•°')
plt.ylabel('è´Ÿè· (kW)')
plt.xticks(hours[::2])  # æ¯2å°æ—¶æ ‡ä¸€ä¸ªåˆ»åº¦
plt.legend(fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('prediction_comparison.png', dpi=300, bbox_inches='tight')
plt.show()
print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæ¯•ï¼ç»“æœå·²ä¿å­˜ä¸ºï¼štraining_loss.png å’Œ prediction_comparison.png")

# å¯è§†åŒ–ï¼šé¢„æµ‹æ•ˆæœå¯¹æ¯”ï¼ˆå°†å‰5ä¸ªæµ‹è¯•æ ·æœ¬è¿æˆ120ä¸ªç‚¹ï¼‰
plt.figure(figsize=(15, 6))

# å°†å‰5ä¸ªæ ·æœ¬çš„çœŸå®å€¼å’Œé¢„æµ‹å€¼è¿æ¥æˆ120ä¸ªç‚¹
y_test_concat = np.concatenate([y_test_inv[i] for i in range(min(5, len(y_test_inv)))])
y_pred_concat = np.concatenate([y_pred_inv[i] for i in range(min(5, len(y_pred_inv)))])

# åˆ›å»º120ä¸ªå°æ—¶çš„æ—¶é—´è½´
hours_120 = np.arange(1, len(y_test_concat) + 1)

# ç»˜åˆ¶è¿æ¥çš„120ä¸ªç‚¹
plt.plot(hours_120, y_test_concat, 'bo-', label='çœŸå®å€¼(å‰5æ ·æœ¬)', linewidth=1.5, markersize=4)
plt.plot(hours_120, y_pred_concat, 'r^--', label='é¢„æµ‹å€¼(å‰5æ ·æœ¬)', linewidth=1.5, markersize=4)

# æ·»åŠ æ¯24å°æ—¶çš„åˆ†éš”çº¿æ¥æ ‡è¯†ä¸åŒçš„æ ·æœ¬
for i in range(1, 5):
    plt.axvline(x=i*24, color='gray', linestyle=':', alpha=0.7, linewidth=1)
    plt.text(i*24-12, plt.ylim()[1]*0.95, f'æ ·æœ¬{i}', ha='center', va='top', 
             fontsize=10, bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))

# è®¡ç®—æ•´ä½“MAE
overall_mae = mean_absolute_error(y_test_concat, y_pred_concat)

plt.title(f'è¿ç»­120å°æ—¶è´Ÿè·é¢„æµ‹å¯¹æ¯”ï¼ˆå‰5ä¸ªæµ‹è¯•æ ·æœ¬ï¼‰\næ€»ä½“MAE={overall_mae:.3f}kW', fontsize=14)
plt.xlabel('è¿ç»­å°æ—¶æ•° (120å°æ—¶ = 5ä¸ªæ ·æœ¬ Ã— 24å°æ—¶)')
plt.ylabel('è´Ÿè· (kW)')
plt.xticks(range(0, 121, 12))  # æ¯12å°æ—¶æ ‡ä¸€ä¸ªåˆ»åº¦
plt.legend(fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('prediction_comparison_120hours.png', dpi=300, bbox_inches='tight')
plt.show()